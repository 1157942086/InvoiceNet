{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InvoiceNet\n",
    "I used the processed version of the tokens from the 'group' column strored in the 'type' column of the dataframe for classification. I generate the vocabulary and the corresponding word vectors for the vocabulary using the word2vec model. Using these word embeddings, each token in the input data is converted into a word vector and these word vectors are joined together to produce a matrix-like version of the input data entity where each slice of the matrix represents the word vector for each word in the input data.\n",
    "\n",
    "A convolution neural network is used to extract information from the word embeddings. A fully-connected layer is connected to the output of the convolution layers. The midpoint information for the data entitiy is concatonated to the output of the last fully-connected layer. A final fully-connected layer is used to produce the class prediction. Dropout is used in the fully-connected layers to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "from gensim.models import Word2Vec\n",
    "# Dependencies for the DataHandler Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataHandler\n",
    "DataHandler class takes in a pandas dataframe as input and provides functions to process and prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, data=None, max_len=10):\n",
    "        self.data = data\n",
    "        self.max_length = max_len\n",
    "        self.vocab_size = 0\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.embeddings = None\n",
    "        self.embed_size = 300\n",
    "        self.PAD = '<pad>'\n",
    "        self.UNKNOWN = '<unk>'\n",
    "        self.START = '<start>'\n",
    "        self.END = '<end>'\n",
    "        self.label_dict = {0: 0, 1: 1, 2: 2, 8: 3, 14: 4, 18: 5}\n",
    "        self.num_classes = len(self.label_dict)\n",
    "        self.train_data = {}\n",
    "        # self.type_dict = {'text': 0.1, 'number': 0.2, 'email': 0.3, 'date': 0.4, '': 0.5, 'money': 0.6, 'phone': 0.7}\n",
    "\n",
    "    def read(self, data, max_len=10):\n",
    "        \"\"\"Read DataFrame\"\"\"\n",
    "        self.data = data\n",
    "        self.max_length = max_len\n",
    "\n",
    "    def process_data(self, tokens, coordinates):\n",
    "        tokens = [self.START] + tokens[:self.max_length - 2] + [self.END]\n",
    "        tokens += [self.PAD] * (self.max_length - len(tokens))\n",
    "        inp = np.array([self.get_word_id(token) for token in tokens])\n",
    "        coordinates = np.array(coordinates)\n",
    "        return inp, coordinates\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepares data for training\"\"\"\n",
    "        inputs = []\n",
    "        labels = []\n",
    "        coordinates = []\n",
    "\n",
    "        for i, row in self.data.iterrows():\n",
    "            text = row['type']\n",
    "            coords = row['coords']\n",
    "            label = self.label_dict[int(row['label'])]\n",
    "            tokens = text[0].strip().split(' ')\n",
    "            # dtypes = [self.type_dict[dtype] for dtype in text[1].split(',')]\n",
    "            height = float(text[-2])\n",
    "            width = float(text[-1])\n",
    "            min_x = float(coords[0]) / width\n",
    "            min_y = float(coords[1]) / height\n",
    "            max_x = float(coords[2]) / width\n",
    "            max_y = float(coords[3]) / height\n",
    "\n",
    "            tokens = [self.START] + tokens[:self.max_length - 2] + [self.END]\n",
    "            tokens += [self.PAD] * (self.max_length - len(tokens))\n",
    "            inp = [self.get_word_id(token) for token in tokens]\n",
    "\n",
    "            inputs.append(np.array(inp))\n",
    "            labels.append(np.array(label))\n",
    "            coordinates.append(np.array([min_x, min_y, max_x, max_y]))\n",
    "\n",
    "        self.train_data['inputs'] = np.array(inputs)\n",
    "        self.train_data['labels'] = np.array(labels)\n",
    "        self.train_data['coordinates'] = np.array(coordinates)\n",
    "\n",
    "    def load_embeddings(self, model_path):\n",
    "        \"\"\"Loads pre-trained gensim model\"\"\"\n",
    "        print(\"\\nLoading pre-trained embeddings...\")\n",
    "\n",
    "        model = Word2Vec.load(model_path)\n",
    "        words = list(model.wv.vocab)\n",
    "        embed_size = model.layer1_size\n",
    "\n",
    "        embed = []\n",
    "        word2idx = {self.PAD: 0, self.UNKNOWN: 1, self.START: 2, self.END: 3}\n",
    "        idx2word = {0: self.PAD, 1: self.UNKNOWN, 2: self.START, 3: self.END}\n",
    "\n",
    "        embed.append(np.zeros(embed_size, dtype=np.float32))\n",
    "        embed.append(np.random.uniform(-0.1, 0.1, embed_size))\n",
    "        embed.append(np.random.uniform(-0.1, 0.1, embed_size))\n",
    "        embed.append(np.random.uniform(-0.1, 0.1, embed_size))\n",
    "\n",
    "        for word in words:\n",
    "            vector = model.wv[word]\n",
    "            embed.append(vector)\n",
    "            word2idx[word] = len(word2idx)\n",
    "            idx2word[word2idx[word]] = word\n",
    "\n",
    "        self.vocab_size = len(word2idx)\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.embeddings = np.array(embed, dtype=np.float32)\n",
    "\n",
    "        print(\"\\nSuccessfully loaded pre-trained embeddings!\")\n",
    "\n",
    "    def get_word_id(self, token):\n",
    "        \"\"\"Returns the id of a token\"\"\"\n",
    "        token = token.lower()\n",
    "        if token in self.word2idx:\n",
    "            return self.word2idx[token]\n",
    "        return self.word2idx[self.UNKNOWN]\n",
    "\n",
    "    def save_data(self, out_path='./data/processed.pkl.gz'):\n",
    "        \"\"\"Saves the embeddings and vocab as a zipped pickle file\"\"\"\n",
    "        assert (self.embeddings is not None or self.word2idx), \"Data has not been processed yet\"\n",
    "        pkl = {'embeddings': self.embeddings,\n",
    "               'word2idx': self.word2idx,\n",
    "               'idx2word': self.idx2word\n",
    "               }\n",
    "        with gzip.open(out_path, 'wb') as out_file:\n",
    "            pickle.dump(pkl, out_file)\n",
    "        print(\"\\nData stored as {}\".format(out_path))\n",
    "\n",
    "    def load_data(self, path):\n",
    "        \"\"\"Loads embeddings and vocab from a zipped pickle file\"\"\"\n",
    "        with gzip.open(path, 'rb') as in_file:\n",
    "            pkl = pickle.load(in_file)\n",
    "        self.embeddings = pkl['embeddings']\n",
    "        self.embed_size = self.embeddings.shape[1]\n",
    "        self.word2idx = pkl['word2idx']\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "        self.idx2word = pkl['idx2word']\n",
    "        print(\"\\nSuccessfully loaded data from {}\".format(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim - Word2Vec\n",
    "We use gensim word2vec implementation to train vector embeddings for our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "# Dependencies for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=689, size=300, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naivehobo/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('train_api.pk', 'rb') as pklfile:\n",
    "    df = pickle.load(pklfile)\n",
    "\n",
    "sentences = []\n",
    "\n",
    "# Iterate through all the rows of the dataframe and split each processed \n",
    "for i, row in df.iterrows():\n",
    "    text = row['type'][0].strip()\n",
    "    sentences.append(text.split(' '))\n",
    "\n",
    "model = Word2Vec(sentences, size=300, window=5, min_count=3, workers=4)\n",
    "model.save('model.bin')\n",
    "print(model)\n",
    "\n",
    "X = model[model.wv.vocab]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "\n",
    "words = list(model.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InvoiceNet - Model\n",
    "The InvoiceNet class builds the model architecture and provides utility functions to train the model, perform inference on a trained model and load saved weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, concatenate\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D\n",
    "from keras import regularizers\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Dependencies for InvoiceNet class\n",
    "\n",
    "# Setting random seed\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceNet:\n",
    "\n",
    "    def __init__(self, data_handler, config):\n",
    "        coordinates = Input(shape=(data_handler.train_data['coordinates'].shape[1],), dtype='float32', name='coordinates')\n",
    "        words_input = Input(shape=(data_handler.max_length,), dtype='int32', name='words_input')\n",
    "        words = Embedding(data_handler.embeddings.shape[0], data_handler.embeddings.shape[1],\n",
    "                          weights=[data_handler.embeddings],\n",
    "                          trainable=False)(words_input)\n",
    "\n",
    "        conv1 = Convolution1D(filters=config.num_filters,\n",
    "                              kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              strides=1,\n",
    "                              kernel_regularizer=regularizers.l2(config.reg_rate))(words)\n",
    "        pool1 = GlobalMaxPooling1D()(conv1)\n",
    "\n",
    "        conv2 = Convolution1D(filters=config.num_filters,\n",
    "                              kernel_size=4,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              strides=1,\n",
    "                              kernel_regularizer=regularizers.l2(config.reg_rate))(words)\n",
    "        pool2 = GlobalMaxPooling1D()(conv2)\n",
    "\n",
    "        conv3 = Convolution1D(filters=config.num_filters,\n",
    "                              kernel_size=5,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              strides=1,\n",
    "                              kernel_regularizer=regularizers.l2(config.reg_rate))(words)\n",
    "        pool3 = GlobalMaxPooling1D()(conv3)\n",
    "\n",
    "        output = concatenate([pool1, pool2, pool3])\n",
    "        output = Dropout(0.5)(output)\n",
    "        output = concatenate([output, coordinates])\n",
    "        output = Dense(config.num_hidden, activation='relu')(output)\n",
    "        output = Dropout(0.5)(output)\n",
    "        output = Dense(data_handler.num_classes, activation='softmax')(output)\n",
    "\n",
    "        self.model = Model(inputs=[words_input, coordinates], outputs=[output])\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "        # self.model.summary()\n",
    "        self.data_handler = data_handler\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        print(\"\\nInitializing training...\")\n",
    "\n",
    "        if not os.path.exists(self.config.log_dir):\n",
    "            os.makedirs(self.config.log_dir)\n",
    "\n",
    "        if not os.path.exists(self.config.checkpoint_dir):\n",
    "            os.makedirs(self.config.checkpoint_dir)\n",
    "\n",
    "        if not os.path.exists(self.config.model_path):\n",
    "            os.makedirs(self.config.model_path)\n",
    "\n",
    "        tensorboard = keras.callbacks.TensorBoard(log_dir=self.config.log_dir, histogram_freq=1, write_graph=True)\n",
    "        modelcheckpoints = keras.callbacks.ModelCheckpoint(os.path.join(self.config.checkpoint_dir, \"InvoiceNet_\") +\n",
    "                                                           \".{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.hdf5\",\n",
    "                                                           monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                                                           save_weights_only=False, mode='auto')\n",
    "\n",
    "        class_weights = compute_class_weight('balanced', np.unique(self.data_handler.train_data['labels']), self.data_handler.train_data['labels'])\n",
    "        d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        self.model.fit([self.data_handler.train_data['inputs'], self.data_handler.train_data['coordinates']],\n",
    "                       self.data_handler.train_data['labels'],\n",
    "                       batch_size=self.config.batch_size,\n",
    "                       verbose=True,\n",
    "                       epochs=self.config.num_epochs,\n",
    "                       callbacks=[tensorboard, modelcheckpoints],\n",
    "                       validation_split=0.125,\n",
    "                       shuffle=self.config.shuffle,\n",
    "                       class_weight=d_class_weights)\n",
    "\n",
    "        self.model.save_weights(os.path.join(self.config.model_path, \"InvoiceNet.model\"))\n",
    "\n",
    "    def load_weights(self, path):\n",
    "        \"\"\"Loads weights from the given model file\"\"\"\n",
    "        self.model.load_weights(path)\n",
    "        print(\"\\nSuccessfully loaded weights from {}\".format(path))\n",
    "\n",
    "    def predict(self, tokens, coordinates):\n",
    "        \"\"\"Performs inference on the given tokens and coordinates\"\"\"\n",
    "        inp, coords = self.data_handler.process_data(tokens, coordinates)\n",
    "        pred = self.model.predict([inp, coords], verbose=True)\n",
    "        pred = pred.argmax(axis=-1)\n",
    "        return pred\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions = self.model.predict([self.data_handler.train_data['inputs'], self.data_handler.train_data['coordinates']], verbose=True)\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "        acc = np.sum(predictions == self.data_handler.train_data['labels']) / float(len(self.data_handler.train_data['labels']))\n",
    "        print(\"\\nTest Accuracy: {}\".format(acc))\n",
    "        return predictions\n",
    "\n",
    "    @staticmethod\n",
    "    def get_precision(predictions, true_labels, target_label):\n",
    "        target_label_count = 0\n",
    "        correct_target_label_count = 0\n",
    "\n",
    "        for idx in xrange(len(predictions)):\n",
    "            if predictions[idx] == target_label:\n",
    "                target_label_count += 1\n",
    "                if predictions[idx] == true_labels[idx]:\n",
    "                    correct_target_label_count += 1\n",
    "\n",
    "        if correct_target_label_count == 0:\n",
    "            return 0\n",
    "        return float(correct_target_label_count) / target_label_count\n",
    "\n",
    "    def f1_score(self, predictions):\n",
    "        f1_sum = 0\n",
    "        f1_count = 0\n",
    "        for target_label in xrange(0, max(self.data_handler.train_data['labels'])):\n",
    "            precision = self.get_precision(predictions, self.data_handler.train_data['labels'], target_label)\n",
    "            recall = self.get_precision(self.data_handler.train_data['labels'], predictions, target_label)\n",
    "            f1 = 0 if (precision+recall) == 0 else 2*precision*recall/(precision+recall)\n",
    "            f1_sum += f1\n",
    "            f1_count += 1\n",
    "\n",
    "        macrof1 = f1_sum / float(f1_count)\n",
    "        print(\"\\nMacro-Averaged F1: %.4f\\n\" % macrof1)\n",
    "        return macrof1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "Config class to define training/testing parameters. Change mode to 'test' to run the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, data):\n",
    "        self.data = data                                # path to training or testing data\n",
    "        self.word2vec = \"model.bin\"                     # path to trained word2vec model\n",
    "        self.model_path = \"./model\"                     # path to directory where trained model should be stored\n",
    "        self.load_weights = \"./model/InvoiceNet.model\"  # path to saved weights file\n",
    "        self.checkpoint_dir = \"./checkpoints\"           # path to directory where checkpoints should be stored\n",
    "        self.log_dir = \"./logs\"                         # path to directory where tensorboard logs should be stored\n",
    "        self.num_epochs = 200                           # number of epochs\n",
    "        self.num_hidden = 512                           # size of hidden layer\n",
    "        self.num_filters = 100                          # number of filters\n",
    "        self.batch_size = 64                            # size of mini-batch\n",
    "        self.reg_rate = 0.0001                          # rate of regularization\n",
    "        self.shuffle = True                             # shuffle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading pre-trained embeddings...\n",
      "\n",
      "Successfully loaded pre-trained embeddings!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naivehobo/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:68: DeprecationWarning: Call to deprecated `layer1_size` (Attribute will be removed in 4.0.0, use self.trainables.layer1_size instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 12)\n",
      "(4754,)\n",
      "(4754, 4)\n",
      "\n",
      "Initializing training...\n",
      "Train on 4159 samples, validate on 595 samples\n",
      "Epoch 1/200\n",
      "4159/4159 [==============================] - 2s 548us/step - loss: 1.8490 - acc: 0.3460 - val_loss: 1.2869 - val_acc: 0.0353\n",
      "Epoch 2/200\n",
      "4159/4159 [==============================] - 1s 235us/step - loss: 1.6811 - acc: 0.1897 - val_loss: 1.2626 - val_acc: 0.0286\n",
      "Epoch 3/200\n",
      "4159/4159 [==============================] - 1s 235us/step - loss: 1.5829 - acc: 0.1885 - val_loss: 1.1617 - val_acc: 0.2605\n",
      "Epoch 4/200\n",
      "4159/4159 [==============================] - 1s 235us/step - loss: 1.5316 - acc: 0.2101 - val_loss: 1.0761 - val_acc: 0.1983\n",
      "Epoch 5/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 1.4924 - acc: 0.2390 - val_loss: 1.1522 - val_acc: 0.2739\n",
      "Epoch 6/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 1.3861 - acc: 0.2941 - val_loss: 1.0306 - val_acc: 0.2840\n",
      "Epoch 7/200\n",
      "4159/4159 [==============================] - 1s 249us/step - loss: 1.3271 - acc: 0.3119 - val_loss: 0.9723 - val_acc: 0.3025\n",
      "Epoch 8/200\n",
      "4159/4159 [==============================] - 1s 237us/step - loss: 1.3545 - acc: 0.3203 - val_loss: 0.9171 - val_acc: 0.2605\n",
      "Epoch 9/200\n",
      "4159/4159 [==============================] - 1s 237us/step - loss: 1.2544 - acc: 0.3212 - val_loss: 0.8439 - val_acc: 0.3966\n",
      "Epoch 10/200\n",
      "4159/4159 [==============================] - 1s 249us/step - loss: 1.1911 - acc: 0.3559 - val_loss: 0.7672 - val_acc: 0.3933\n",
      "Epoch 11/200\n",
      "4159/4159 [==============================] - 1s 239us/step - loss: 1.1735 - acc: 0.3729 - val_loss: 0.7848 - val_acc: 0.4286\n",
      "Epoch 12/200\n",
      "4159/4159 [==============================] - 1s 237us/step - loss: 1.2352 - acc: 0.3741 - val_loss: 0.8915 - val_acc: 0.3277\n",
      "Epoch 13/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 1.1596 - acc: 0.3294 - val_loss: 0.8503 - val_acc: 0.2605\n",
      "Epoch 14/200\n",
      "4159/4159 [==============================] - 1s 248us/step - loss: 1.0912 - acc: 0.3982 - val_loss: 0.7624 - val_acc: 0.4487\n",
      "Epoch 15/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 1.0913 - acc: 0.4049 - val_loss: 0.7170 - val_acc: 0.2941\n",
      "Epoch 16/200\n",
      "4159/4159 [==============================] - 1s 246us/step - loss: 1.1005 - acc: 0.3587 - val_loss: 0.7840 - val_acc: 0.2454\n",
      "Epoch 17/200\n",
      "4159/4159 [==============================] - 1s 247us/step - loss: 1.0654 - acc: 0.3876 - val_loss: 0.6903 - val_acc: 0.3563\n",
      "Epoch 18/200\n",
      "4159/4159 [==============================] - 1s 238us/step - loss: 1.0361 - acc: 0.4008 - val_loss: 0.7501 - val_acc: 0.4622\n",
      "Epoch 19/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.9846 - acc: 0.4316 - val_loss: 0.7399 - val_acc: 0.4101\n",
      "Epoch 20/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 1.0663 - acc: 0.4020 - val_loss: 0.7605 - val_acc: 0.4218\n",
      "Epoch 21/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.9756 - acc: 0.3857 - val_loss: 0.6960 - val_acc: 0.4958\n",
      "Epoch 22/200\n",
      "4159/4159 [==============================] - 1s 238us/step - loss: 1.0455 - acc: 0.3907 - val_loss: 0.7083 - val_acc: 0.3529\n",
      "Epoch 23/200\n",
      "4159/4159 [==============================] - 1s 240us/step - loss: 0.9307 - acc: 0.4265 - val_loss: 0.6323 - val_acc: 0.4891\n",
      "Epoch 24/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 0.9799 - acc: 0.4263 - val_loss: 0.6897 - val_acc: 0.3345\n",
      "Epoch 25/200\n",
      "4159/4159 [==============================] - 1s 242us/step - loss: 0.9971 - acc: 0.3893 - val_loss: 0.6386 - val_acc: 0.4437\n",
      "Epoch 26/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 0.9110 - acc: 0.4362 - val_loss: 0.6627 - val_acc: 0.4235\n",
      "Epoch 27/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 0.9845 - acc: 0.4157 - val_loss: 0.6974 - val_acc: 0.4370\n",
      "Epoch 28/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 0.9806 - acc: 0.4210 - val_loss: 0.6633 - val_acc: 0.4084\n",
      "Epoch 29/200\n",
      "4159/4159 [==============================] - 1s 240us/step - loss: 0.9106 - acc: 0.4229 - val_loss: 0.6047 - val_acc: 0.5261\n",
      "Epoch 30/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 0.9195 - acc: 0.4523 - val_loss: 0.6357 - val_acc: 0.3597\n",
      "Epoch 31/200\n",
      "4159/4159 [==============================] - 1s 228us/step - loss: 0.9190 - acc: 0.4018 - val_loss: 0.6643 - val_acc: 0.4185\n",
      "Epoch 32/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.9149 - acc: 0.4619 - val_loss: 0.6445 - val_acc: 0.3849\n",
      "Epoch 33/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.8953 - acc: 0.4448 - val_loss: 0.6135 - val_acc: 0.4588\n",
      "Epoch 34/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.9228 - acc: 0.4210 - val_loss: 0.7085 - val_acc: 0.4773\n",
      "Epoch 35/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.8841 - acc: 0.4494 - val_loss: 0.6722 - val_acc: 0.4975\n",
      "Epoch 36/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.8554 - acc: 0.4583 - val_loss: 0.6127 - val_acc: 0.5563\n",
      "Epoch 37/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.8406 - acc: 0.4761 - val_loss: 0.6174 - val_acc: 0.4739\n",
      "Epoch 38/200\n",
      "4159/4159 [==============================] - 1s 234us/step - loss: 0.8775 - acc: 0.4489 - val_loss: 0.6642 - val_acc: 0.4807\n",
      "Epoch 39/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.8972 - acc: 0.4496 - val_loss: 0.6199 - val_acc: 0.5193\n",
      "Epoch 40/200\n",
      "4159/4159 [==============================] - 1s 234us/step - loss: 0.8557 - acc: 0.4314 - val_loss: 0.6265 - val_acc: 0.5294\n",
      "Epoch 41/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.9408 - acc: 0.4321 - val_loss: 0.6577 - val_acc: 0.4555\n",
      "Epoch 42/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.8485 - acc: 0.4588 - val_loss: 0.5951 - val_acc: 0.4790\n",
      "Epoch 43/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.9175 - acc: 0.4511 - val_loss: 0.6515 - val_acc: 0.4975\n",
      "Epoch 44/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.8865 - acc: 0.4701 - val_loss: 0.6168 - val_acc: 0.5563\n",
      "Epoch 45/200\n",
      "4159/4159 [==============================] - 1s 225us/step - loss: 0.8181 - acc: 0.4763 - val_loss: 0.6148 - val_acc: 0.5378\n",
      "Epoch 46/200\n",
      "4159/4159 [==============================] - 1s 228us/step - loss: 0.7967 - acc: 0.4828 - val_loss: 0.6439 - val_acc: 0.4723\n",
      "Epoch 47/200\n",
      "4159/4159 [==============================] - 1s 226us/step - loss: 0.8060 - acc: 0.4864 - val_loss: 0.6418 - val_acc: 0.5059\n",
      "Epoch 48/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7825 - acc: 0.4922 - val_loss: 0.6126 - val_acc: 0.5462\n",
      "Epoch 49/200\n",
      "4159/4159 [==============================] - 1s 226us/step - loss: 0.8081 - acc: 0.4939 - val_loss: 0.5976 - val_acc: 0.5143\n",
      "Epoch 50/200\n",
      "4159/4159 [==============================] - 1s 226us/step - loss: 0.7532 - acc: 0.5073 - val_loss: 0.5901 - val_acc: 0.5647\n",
      "Epoch 51/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.7998 - acc: 0.5057 - val_loss: 0.6154 - val_acc: 0.5143\n",
      "Epoch 52/200\n",
      "4159/4159 [==============================] - 1s 228us/step - loss: 0.8011 - acc: 0.4705 - val_loss: 0.5978 - val_acc: 0.4891\n",
      "Epoch 53/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7979 - acc: 0.4840 - val_loss: 0.6304 - val_acc: 0.5395\n",
      "Epoch 54/200\n",
      "4159/4159 [==============================] - 1s 228us/step - loss: 0.8193 - acc: 0.4975 - val_loss: 0.6400 - val_acc: 0.5731\n",
      "Epoch 55/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.7516 - acc: 0.4987 - val_loss: 0.6480 - val_acc: 0.5345\n",
      "Epoch 56/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.8019 - acc: 0.5008 - val_loss: 0.6556 - val_acc: 0.5277\n",
      "Epoch 57/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.8095 - acc: 0.4977 - val_loss: 0.7045 - val_acc: 0.5378\n",
      "Epoch 58/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.7942 - acc: 0.5126 - val_loss: 0.5784 - val_acc: 0.5042\n",
      "Epoch 59/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.8104 - acc: 0.4946 - val_loss: 0.6515 - val_acc: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7441 - acc: 0.4970 - val_loss: 0.6063 - val_acc: 0.4992\n",
      "Epoch 61/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.7474 - acc: 0.4958 - val_loss: 0.6270 - val_acc: 0.5832\n",
      "Epoch 62/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.7631 - acc: 0.5170 - val_loss: 0.6088 - val_acc: 0.5378\n",
      "Epoch 63/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7382 - acc: 0.5078 - val_loss: 0.6447 - val_acc: 0.5529\n",
      "Epoch 64/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7747 - acc: 0.5071 - val_loss: 0.6455 - val_acc: 0.5059\n",
      "Epoch 65/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7803 - acc: 0.5013 - val_loss: 0.6868 - val_acc: 0.5445\n",
      "Epoch 66/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7697 - acc: 0.5083 - val_loss: 0.6206 - val_acc: 0.4571\n",
      "Epoch 67/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.7395 - acc: 0.4917 - val_loss: 0.6428 - val_acc: 0.6034\n",
      "Epoch 68/200\n",
      "4159/4159 [==============================] - 1s 235us/step - loss: 0.7865 - acc: 0.5025 - val_loss: 0.6811 - val_acc: 0.5311\n",
      "Epoch 69/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.7601 - acc: 0.5097 - val_loss: 0.6398 - val_acc: 0.5210\n",
      "Epoch 70/200\n",
      "4159/4159 [==============================] - 1s 238us/step - loss: 0.7331 - acc: 0.4917 - val_loss: 0.6186 - val_acc: 0.5882\n",
      "Epoch 71/200\n",
      "4159/4159 [==============================] - 1s 237us/step - loss: 0.7751 - acc: 0.4891 - val_loss: 0.6336 - val_acc: 0.5546\n",
      "Epoch 72/200\n",
      "4159/4159 [==============================] - 1s 234us/step - loss: 0.7504 - acc: 0.4960 - val_loss: 0.5942 - val_acc: 0.5261\n",
      "Epoch 73/200\n",
      "4159/4159 [==============================] - 1s 233us/step - loss: 0.6662 - acc: 0.5396 - val_loss: 0.6642 - val_acc: 0.6017\n",
      "Epoch 74/200\n",
      "4159/4159 [==============================] - 1s 233us/step - loss: 0.7533 - acc: 0.5057 - val_loss: 0.6457 - val_acc: 0.5445\n",
      "Epoch 75/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.7877 - acc: 0.5018 - val_loss: 0.6084 - val_acc: 0.4739\n",
      "Epoch 76/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.8019 - acc: 0.4939 - val_loss: 0.5957 - val_acc: 0.4252\n",
      "Epoch 77/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.7680 - acc: 0.4977 - val_loss: 0.5584 - val_acc: 0.5580\n",
      "Epoch 78/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.6815 - acc: 0.5446 - val_loss: 0.5741 - val_acc: 0.5244\n",
      "Epoch 79/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7695 - acc: 0.5052 - val_loss: 0.6423 - val_acc: 0.4975\n",
      "Epoch 80/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7398 - acc: 0.4941 - val_loss: 0.5903 - val_acc: 0.5563\n",
      "Epoch 81/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.7397 - acc: 0.5078 - val_loss: 0.6768 - val_acc: 0.5731\n",
      "Epoch 82/200\n",
      "4159/4159 [==============================] - 1s 250us/step - loss: 0.7048 - acc: 0.5201 - val_loss: 0.6350 - val_acc: 0.5563\n",
      "Epoch 83/200\n",
      "4159/4159 [==============================] - 1s 248us/step - loss: 0.7393 - acc: 0.5090 - val_loss: 0.5819 - val_acc: 0.5429\n",
      "Epoch 84/200\n",
      "4159/4159 [==============================] - 1s 238us/step - loss: 0.7030 - acc: 0.5167 - val_loss: 0.6158 - val_acc: 0.5496\n",
      "Epoch 85/200\n",
      "4159/4159 [==============================] - 1s 251us/step - loss: 0.7509 - acc: 0.4972 - val_loss: 0.6089 - val_acc: 0.5496\n",
      "Epoch 86/200\n",
      "4159/4159 [==============================] - 1s 245us/step - loss: 0.7170 - acc: 0.5213 - val_loss: 0.6204 - val_acc: 0.4672\n",
      "Epoch 87/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.7175 - acc: 0.5032 - val_loss: 0.6018 - val_acc: 0.5513\n",
      "Epoch 88/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6918 - acc: 0.5451 - val_loss: 0.6042 - val_acc: 0.5597\n",
      "Epoch 89/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6797 - acc: 0.5114 - val_loss: 0.6208 - val_acc: 0.5361\n",
      "Epoch 90/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6985 - acc: 0.5167 - val_loss: 0.5549 - val_acc: 0.5361\n",
      "Epoch 91/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.6725 - acc: 0.5052 - val_loss: 0.6421 - val_acc: 0.5748\n",
      "Epoch 92/200\n",
      "4159/4159 [==============================] - 1s 242us/step - loss: 0.7306 - acc: 0.5549 - val_loss: 0.6199 - val_acc: 0.5580\n",
      "Epoch 93/200\n",
      "4159/4159 [==============================] - 1s 242us/step - loss: 0.7187 - acc: 0.5001 - val_loss: 0.6099 - val_acc: 0.5294\n",
      "Epoch 94/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 0.6650 - acc: 0.5619 - val_loss: 0.6154 - val_acc: 0.5597\n",
      "Epoch 95/200\n",
      "4159/4159 [==============================] - 1s 245us/step - loss: 0.7287 - acc: 0.5246 - val_loss: 0.6040 - val_acc: 0.5529\n",
      "Epoch 96/200\n",
      "4159/4159 [==============================] - 1s 234us/step - loss: 0.6435 - acc: 0.5523 - val_loss: 0.5887 - val_acc: 0.5748\n",
      "Epoch 97/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6557 - acc: 0.5220 - val_loss: 0.6255 - val_acc: 0.5261\n",
      "Epoch 98/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6973 - acc: 0.5165 - val_loss: 0.5442 - val_acc: 0.5529\n",
      "Epoch 99/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.7619 - acc: 0.5198 - val_loss: 0.6062 - val_acc: 0.5126\n",
      "Epoch 100/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6736 - acc: 0.5494 - val_loss: 0.6446 - val_acc: 0.5513\n",
      "Epoch 101/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6646 - acc: 0.5453 - val_loss: 0.6058 - val_acc: 0.5412\n",
      "Epoch 102/200\n",
      "4159/4159 [==============================] - 1s 242us/step - loss: 0.6761 - acc: 0.5528 - val_loss: 0.6293 - val_acc: 0.5597\n",
      "Epoch 103/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6791 - acc: 0.5323 - val_loss: 0.5910 - val_acc: 0.5664\n",
      "Epoch 104/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.6912 - acc: 0.5427 - val_loss: 0.6285 - val_acc: 0.5378\n",
      "Epoch 105/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.6575 - acc: 0.5338 - val_loss: 0.6300 - val_acc: 0.5429\n",
      "Epoch 106/200\n",
      "4159/4159 [==============================] - 1s 242us/step - loss: 0.7084 - acc: 0.5299 - val_loss: 0.6279 - val_acc: 0.5345\n",
      "Epoch 107/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.6771 - acc: 0.5037 - val_loss: 0.6287 - val_acc: 0.5496\n",
      "Epoch 108/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6743 - acc: 0.5559 - val_loss: 0.6330 - val_acc: 0.5866\n",
      "Epoch 109/200\n",
      "4159/4159 [==============================] - 1s 245us/step - loss: 0.6341 - acc: 0.5694 - val_loss: 0.6627 - val_acc: 0.5849\n",
      "Epoch 110/200\n",
      "4159/4159 [==============================] - 1s 245us/step - loss: 0.6252 - acc: 0.5629 - val_loss: 0.6144 - val_acc: 0.5378\n",
      "Epoch 111/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.7203 - acc: 0.5246 - val_loss: 0.6241 - val_acc: 0.5462\n",
      "Epoch 112/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.6833 - acc: 0.5381 - val_loss: 0.6334 - val_acc: 0.5782\n",
      "Epoch 113/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.7356 - acc: 0.5273 - val_loss: 0.5107 - val_acc: 0.5160\n",
      "Epoch 114/200\n",
      "4159/4159 [==============================] - 1s 245us/step - loss: 0.7937 - acc: 0.5117 - val_loss: 0.6684 - val_acc: 0.5345\n",
      "Epoch 115/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.7066 - acc: 0.4770 - val_loss: 0.5865 - val_acc: 0.5731\n",
      "Epoch 116/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.7660 - acc: 0.5405 - val_loss: 0.6009 - val_acc: 0.5529\n",
      "Epoch 117/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.7000 - acc: 0.5393 - val_loss: 0.5945 - val_acc: 0.5681\n",
      "Epoch 118/200\n",
      "4159/4159 [==============================] - 1s 237us/step - loss: 0.6157 - acc: 0.5542 - val_loss: 0.6765 - val_acc: 0.5765\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6947 - acc: 0.5396 - val_loss: 0.5956 - val_acc: 0.5580\n",
      "Epoch 120/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.7047 - acc: 0.5227 - val_loss: 0.5115 - val_acc: 0.5412\n",
      "Epoch 121/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6401 - acc: 0.5107 - val_loss: 0.6222 - val_acc: 0.5916\n",
      "Epoch 122/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.6126 - acc: 0.5549 - val_loss: 0.6241 - val_acc: 0.5782\n",
      "Epoch 123/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6099 - acc: 0.5535 - val_loss: 0.7451 - val_acc: 0.5664\n",
      "Epoch 124/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6756 - acc: 0.5396 - val_loss: 0.5701 - val_acc: 0.5563\n",
      "Epoch 125/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.7220 - acc: 0.5107 - val_loss: 0.5964 - val_acc: 0.5765\n",
      "Epoch 126/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6671 - acc: 0.5480 - val_loss: 0.5762 - val_acc: 0.5697\n",
      "Epoch 127/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.6642 - acc: 0.5545 - val_loss: 0.5407 - val_acc: 0.5882\n",
      "Epoch 128/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7178 - acc: 0.5206 - val_loss: 0.6540 - val_acc: 0.5664\n",
      "Epoch 129/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6569 - acc: 0.5537 - val_loss: 0.6134 - val_acc: 0.5294\n",
      "Epoch 130/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6827 - acc: 0.5314 - val_loss: 0.5673 - val_acc: 0.5059\n",
      "Epoch 131/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.6820 - acc: 0.5206 - val_loss: 0.6216 - val_acc: 0.5345\n",
      "Epoch 132/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.6825 - acc: 0.5299 - val_loss: 0.5172 - val_acc: 0.5345\n",
      "Epoch 133/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.6655 - acc: 0.5451 - val_loss: 0.6622 - val_acc: 0.5563\n",
      "Epoch 134/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.6183 - acc: 0.5371 - val_loss: 0.5719 - val_acc: 0.5950\n",
      "Epoch 135/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.7034 - acc: 0.5398 - val_loss: 0.6309 - val_acc: 0.5160\n",
      "Epoch 136/200\n",
      "4159/4159 [==============================] - 1s 225us/step - loss: 0.6400 - acc: 0.5242 - val_loss: 0.6020 - val_acc: 0.6050\n",
      "Epoch 137/200\n",
      "4159/4159 [==============================] - ETA: 0s - loss: 0.6747 - acc: 0.544 - 1s 227us/step - loss: 0.6608 - acc: 0.5403 - val_loss: 0.6406 - val_acc: 0.5697\n",
      "Epoch 138/200\n",
      "4159/4159 [==============================] - 1s 227us/step - loss: 0.6301 - acc: 0.5434 - val_loss: 0.6038 - val_acc: 0.5496\n",
      "Epoch 139/200\n",
      "4159/4159 [==============================] - 1s 227us/step - loss: 0.6615 - acc: 0.5328 - val_loss: 0.5882 - val_acc: 0.5092\n",
      "Epoch 140/200\n",
      "4159/4159 [==============================] - 1s 227us/step - loss: 0.6614 - acc: 0.5384 - val_loss: 0.6187 - val_acc: 0.5210\n",
      "Epoch 141/200\n",
      "4159/4159 [==============================] - 1s 227us/step - loss: 0.6226 - acc: 0.5429 - val_loss: 0.6346 - val_acc: 0.5714\n",
      "Epoch 142/200\n",
      "4159/4159 [==============================] - 1s 228us/step - loss: 0.5342 - acc: 0.5564 - val_loss: 0.6826 - val_acc: 0.6017\n",
      "Epoch 143/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.6672 - acc: 0.5581 - val_loss: 0.8074 - val_acc: 0.5479\n",
      "Epoch 144/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.6086 - acc: 0.5588 - val_loss: 0.7127 - val_acc: 0.5882\n",
      "Epoch 145/200\n",
      "4159/4159 [==============================] - 1s 228us/step - loss: 0.6785 - acc: 0.5636 - val_loss: 0.6645 - val_acc: 0.5412\n",
      "Epoch 146/200\n",
      "4159/4159 [==============================] - 1s 229us/step - loss: 0.6118 - acc: 0.5393 - val_loss: 0.6418 - val_acc: 0.5361\n",
      "Epoch 147/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.5742 - acc: 0.5650 - val_loss: 0.6443 - val_acc: 0.5597\n",
      "Epoch 148/200\n",
      "4159/4159 [==============================] - 1s 228us/step - loss: 0.6120 - acc: 0.5761 - val_loss: 0.6796 - val_acc: 0.5849\n",
      "Epoch 149/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6048 - acc: 0.5677 - val_loss: 0.5833 - val_acc: 0.5429\n",
      "Epoch 150/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.5841 - acc: 0.5432 - val_loss: 0.6723 - val_acc: 0.5933\n",
      "Epoch 151/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.5914 - acc: 0.5605 - val_loss: 0.6505 - val_acc: 0.6017\n",
      "Epoch 152/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.5838 - acc: 0.5643 - val_loss: 0.6544 - val_acc: 0.6034\n",
      "Epoch 153/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.6339 - acc: 0.5530 - val_loss: 0.5828 - val_acc: 0.5849\n",
      "Epoch 154/200\n",
      "4159/4159 [==============================] - 1s 235us/step - loss: 0.6597 - acc: 0.5316 - val_loss: 0.6375 - val_acc: 0.5445\n",
      "Epoch 155/200\n",
      "4159/4159 [==============================] - 1s 234us/step - loss: 0.6777 - acc: 0.5436 - val_loss: 0.7008 - val_acc: 0.6000\n",
      "Epoch 156/200\n",
      "4159/4159 [==============================] - 1s 233us/step - loss: 0.6123 - acc: 0.5379 - val_loss: 0.6193 - val_acc: 0.5714\n",
      "Epoch 157/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.5928 - acc: 0.5689 - val_loss: 0.6097 - val_acc: 0.5563\n",
      "Epoch 158/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.6019 - acc: 0.5807 - val_loss: 0.6423 - val_acc: 0.6084\n",
      "Epoch 159/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6078 - acc: 0.5624 - val_loss: 0.6552 - val_acc: 0.6067\n",
      "Epoch 160/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.6069 - acc: 0.5600 - val_loss: 0.6554 - val_acc: 0.5798\n",
      "Epoch 161/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.5667 - acc: 0.5739 - val_loss: 0.6221 - val_acc: 0.5731\n",
      "Epoch 162/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.5702 - acc: 0.5499 - val_loss: 0.6269 - val_acc: 0.5966\n",
      "Epoch 163/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.6408 - acc: 0.5773 - val_loss: 0.6996 - val_acc: 0.5849\n",
      "Epoch 164/200\n",
      "4159/4159 [==============================] - 1s 230us/step - loss: 0.6086 - acc: 0.5475 - val_loss: 0.5805 - val_acc: 0.5479\n",
      "Epoch 165/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.6331 - acc: 0.5718 - val_loss: 0.6222 - val_acc: 0.5445\n",
      "Epoch 166/200\n",
      "4159/4159 [==============================] - 1s 234us/step - loss: 0.6523 - acc: 0.5218 - val_loss: 0.5926 - val_acc: 0.5664\n",
      "Epoch 167/200\n",
      "4159/4159 [==============================] - 1s 247us/step - loss: 0.5884 - acc: 0.5655 - val_loss: 0.5923 - val_acc: 0.5563\n",
      "Epoch 168/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.6111 - acc: 0.5489 - val_loss: 0.6035 - val_acc: 0.5714\n",
      "Epoch 169/200\n",
      "4159/4159 [==============================] - 1s 236us/step - loss: 0.6547 - acc: 0.5600 - val_loss: 0.6422 - val_acc: 0.5529\n",
      "Epoch 170/200\n",
      "4159/4159 [==============================] - 1s 235us/step - loss: 0.6262 - acc: 0.5686 - val_loss: 0.6430 - val_acc: 0.5782\n",
      "Epoch 171/200\n",
      "4159/4159 [==============================] - 1s 242us/step - loss: 0.6057 - acc: 0.5484 - val_loss: 0.6035 - val_acc: 0.6034\n",
      "Epoch 172/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6278 - acc: 0.5612 - val_loss: 0.6495 - val_acc: 0.5479\n",
      "Epoch 173/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.6274 - acc: 0.5535 - val_loss: 0.5487 - val_acc: 0.5445\n",
      "Epoch 174/200\n",
      "4159/4159 [==============================] - 1s 250us/step - loss: 0.5556 - acc: 0.5650 - val_loss: 0.6740 - val_acc: 0.6034\n",
      "Epoch 175/200\n",
      "4159/4159 [==============================] - 1s 241us/step - loss: 0.5455 - acc: 0.5799 - val_loss: 0.6393 - val_acc: 0.6067\n",
      "Epoch 176/200\n",
      "4159/4159 [==============================] - 1s 248us/step - loss: 0.5722 - acc: 0.5569 - val_loss: 0.6365 - val_acc: 0.5714\n",
      "Epoch 177/200\n",
      "4159/4159 [==============================] - 1s 246us/step - loss: 0.6094 - acc: 0.5374 - val_loss: 0.5802 - val_acc: 0.5563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "4159/4159 [==============================] - 1s 244us/step - loss: 0.5705 - acc: 0.5754 - val_loss: 0.5784 - val_acc: 0.5479\n",
      "Epoch 179/200\n",
      "4159/4159 [==============================] - 1s 240us/step - loss: 0.6394 - acc: 0.5694 - val_loss: 0.5972 - val_acc: 0.5008\n",
      "Epoch 180/200\n",
      "4159/4159 [==============================] - 1s 240us/step - loss: 0.6159 - acc: 0.5258 - val_loss: 0.5899 - val_acc: 0.5899\n",
      "Epoch 181/200\n",
      "4159/4159 [==============================] - 1s 242us/step - loss: 0.5762 - acc: 0.5607 - val_loss: 0.5436 - val_acc: 0.5092\n",
      "Epoch 182/200\n",
      "4159/4159 [==============================] - 1s 252us/step - loss: 0.5783 - acc: 0.5434 - val_loss: 0.5879 - val_acc: 0.5697\n",
      "Epoch 183/200\n",
      "4159/4159 [==============================] - 1s 250us/step - loss: 0.5786 - acc: 0.5696 - val_loss: 0.6170 - val_acc: 0.5849\n",
      "Epoch 184/200\n",
      "4159/4159 [==============================] - 1s 245us/step - loss: 0.6679 - acc: 0.5682 - val_loss: 0.6069 - val_acc: 0.5714\n",
      "Epoch 185/200\n",
      "4159/4159 [==============================] - 1s 252us/step - loss: 0.5961 - acc: 0.5511 - val_loss: 0.6053 - val_acc: 0.5328\n",
      "Epoch 186/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.5764 - acc: 0.5393 - val_loss: 0.5896 - val_acc: 0.5496\n",
      "Epoch 187/200\n",
      "4159/4159 [==============================] - 1s 233us/step - loss: 0.6074 - acc: 0.5427 - val_loss: 0.5627 - val_acc: 0.5597\n",
      "Epoch 188/200\n",
      "4159/4159 [==============================] - 1s 232us/step - loss: 0.6098 - acc: 0.5674 - val_loss: 0.5901 - val_acc: 0.5731\n",
      "Epoch 189/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.5469 - acc: 0.5626 - val_loss: 0.5787 - val_acc: 0.5765\n",
      "Epoch 190/200\n",
      "4159/4159 [==============================] - 1s 237us/step - loss: 0.5335 - acc: 0.5581 - val_loss: 0.6370 - val_acc: 0.5832\n",
      "Epoch 191/200\n",
      "4159/4159 [==============================] - 1s 231us/step - loss: 0.5908 - acc: 0.5742 - val_loss: 0.6246 - val_acc: 0.6067\n",
      "Epoch 192/200\n",
      "4159/4159 [==============================] - 1s 234us/step - loss: 0.6786 - acc: 0.5588 - val_loss: 0.5669 - val_acc: 0.5613\n",
      "Epoch 193/200\n",
      "4159/4159 [==============================] - 1s 255us/step - loss: 0.6626 - acc: 0.5396 - val_loss: 0.6293 - val_acc: 0.5479\n",
      "Epoch 194/200\n",
      "4159/4159 [==============================] - 1s 260us/step - loss: 0.6080 - acc: 0.5448 - val_loss: 0.5643 - val_acc: 0.5244\n",
      "Epoch 195/200\n",
      "4159/4159 [==============================] - 1s 254us/step - loss: 0.5607 - acc: 0.5458 - val_loss: 0.5662 - val_acc: 0.5765\n",
      "Epoch 196/200\n",
      "4159/4159 [==============================] - 1s 247us/step - loss: 0.6135 - acc: 0.5763 - val_loss: 0.5531 - val_acc: 0.5664\n",
      "Epoch 197/200\n",
      "4159/4159 [==============================] - 1s 240us/step - loss: 0.6126 - acc: 0.5684 - val_loss: 0.5747 - val_acc: 0.5866\n",
      "Epoch 198/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.6420 - acc: 0.5807 - val_loss: 0.5777 - val_acc: 0.5529\n",
      "Epoch 199/200\n",
      "4159/4159 [==============================] - 1s 250us/step - loss: 0.5701 - acc: 0.5569 - val_loss: 0.5879 - val_acc: 0.5647\n",
      "Epoch 200/200\n",
      "4159/4159 [==============================] - 1s 243us/step - loss: 0.6253 - acc: 0.5665 - val_loss: 0.6363 - val_acc: 0.6202\n"
     ]
    }
   ],
   "source": [
    "# Training the network on the data\n",
    "\n",
    "# Defining a DataHandler object and preparing data for training\n",
    "config = Config(data=\"train_api.pk\")\n",
    "\n",
    "with open(config.data, 'rb') as pklfile:\n",
    "    df = pickle.load(pklfile)\n",
    "\n",
    "data = DataHandler(df, max_len=12)\n",
    "data.load_embeddings(config.word2vec)\n",
    "data.prepare_data()\n",
    "\n",
    "print(data.train_data['inputs'].shape)\n",
    "print(data.train_data['labels'].shape)\n",
    "print(data.train_data['coordinates'].shape)\n",
    "\n",
    "net = InvoiceNet(data_handler=data, config=config)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Runs the model on the test data and calculates the test accuracy and f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading pre-trained embeddings...\n",
      "\n",
      "Successfully loaded pre-trained embeddings!\n",
      "(1023, 12)\n",
      "(1023,)\n",
      "(1023, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naivehobo/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:68: DeprecationWarning: Call to deprecated `layer1_size` (Attribute will be removed in 4.0.0, use self.trainables.layer1_size instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded weights from ./model/InvoiceNet.model\n",
      "1023/1023 [==============================] - 0s 168us/step\n",
      "\n",
      "Test Accuracy: 0.55522971652\n",
      "\n",
      "Macro-Averaged F1: 0.3681\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3680815763419294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {0: \"Other\",\n",
    "              1: \"Invoice Date\",\n",
    "              2: \"Invoice Number\",\n",
    "              3: \"Buyer GST\",\n",
    "              4: \"Seller GST\",\n",
    "              5: \"Total Amount\"}\n",
    "\n",
    "config = Config(data=\"test_api.pk\")\n",
    "\n",
    "with open(config.data, 'rb') as pklfile:\n",
    "    df = pickle.load(pklfile)\n",
    "\n",
    "data = DataHandler(df, max_len=12)\n",
    "data.load_embeddings(config.word2vec)\n",
    "data.prepare_data()\n",
    "\n",
    "print(data.train_data['inputs'].shape)\n",
    "print(data.train_data['labels'].shape)\n",
    "print(data.train_data['coordinates'].shape)\n",
    "\n",
    "net = InvoiceNet(data_handler=data, config=config)\n",
    "\n",
    "net.load_weights(config.load_weights)\n",
    "predictions = net.evaluate()\n",
    "net.f1_score(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
